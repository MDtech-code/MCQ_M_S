# # nlp_generator/ml_generator/model_loader.py

# from transformers import T5Tokenizer, T5ForConditionalGeneration

# # Load model and tokenizer once (shared across app)
# tokenizer = T5Tokenizer.from_pretrained("iarfmoose/t5-base-question-generator")
# model = T5ForConditionalGeneration.from_pretrained("iarfmoose/t5-base-question-generator")
